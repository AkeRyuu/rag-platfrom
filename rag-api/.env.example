# Shared RAG API Configuration

# Server
API_PORT=3100
API_HOST=0.0.0.0

# Qdrant Vector Database
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=

# Embedding Provider: bge-m3-server, ollama, openai
EMBEDDING_PROVIDER=bge-m3-server
BGE_M3_URL=http://localhost:8080
OLLAMA_URL=http://localhost:11434
OLLAMA_EMBEDDING_MODEL=bge-m3
OPENAI_API_KEY=

# LLM Provider: ollama, openai, anthropic
LLM_PROVIDER=ollama
OLLAMA_MODEL=qwen2.5:32b
OPENAI_MODEL=gpt-4-turbo-preview
ANTHROPIC_API_KEY=
ANTHROPIC_MODEL=claude-3-sonnet-20240229

# Vector size (depends on embedding model)
# bge-m3: 1024, openai: 1536, ollama nomic: 768
VECTOR_SIZE=1024

# Redis (optional, for caching)
REDIS_URL=redis://localhost:6380

# Logging: error, warn, info, debug
LOG_LEVEL=info

# Confluence Integration (optional)
# Get API token from: https://id.atlassian.com/manage-profile/security/api-tokens
CONFLUENCE_URL=https://your-domain.atlassian.net
CONFLUENCE_EMAIL=your-email@example.com
CONFLUENCE_API_TOKEN=
