/**
 * Agent Memory Service - Persistent memory storage for AI agents
 *
 * Stores and retrieves memories using Qdrant vector database for semantic search.
 */

import { v4 as uuidv4 } from 'uuid';
import { vectorStore, VectorPoint } from './vector-store';
import { embeddingService } from './embedding';
import { llm } from './llm';
import { logger } from '../utils/logger';

export type MemoryType = 'decision' | 'insight' | 'context' | 'todo' | 'conversation' | 'note';
export type MemorySource = 'manual' | 'auto_conversation' | 'auto_pattern' | 'auto_feedback';
export type TodoStatus = 'pending' | 'in_progress' | 'done' | 'cancelled';

export interface Memory {
  id: string;
  type: MemoryType;
  content: string;
  tags: string[];
  relatedTo?: string;
  createdAt: string;
  updatedAt: string;
  metadata?: Record<string, unknown>;
  // For todos
  status?: TodoStatus;
  statusHistory?: { status: TodoStatus; timestamp: string; note?: string }[];
  // Auto-learning fields
  source?: MemorySource;
  confidence?: number; // 0-1 confidence score for auto-extracted memories
  validated?: boolean; // User validation status
  originalContext?: string; // Source conversation/context
}

export interface MemorySearchResult {
  memory: Memory;
  score: number;
}

export interface CreateMemoryOptions {
  projectName: string;
  content: string;
  type?: MemoryType;
  tags?: string[];
  relatedTo?: string;
  metadata?: Record<string, unknown>;
}

export interface SearchMemoryOptions {
  projectName: string;
  query: string;
  type?: MemoryType | 'all';
  limit?: number;
  tag?: string;
}

export interface ListMemoryOptions {
  projectName: string;
  type?: MemoryType | 'all';
  tag?: string;
  limit?: number;
}

class MemoryService {
  private getCollectionName(projectName: string): string {
    return `${projectName}_agent_memory`;
  }

  /**
   * Store a new memory
   */
  async remember(options: CreateMemoryOptions): Promise<Memory> {
    const { projectName, content, type = 'note', tags = [], relatedTo, metadata } = options;
    const collectionName = this.getCollectionName(projectName);

    const memory: Memory = {
      id: uuidv4(),
      type,
      content,
      tags,
      relatedTo,
      createdAt: new Date().toISOString(),
      updatedAt: new Date().toISOString(),
      metadata,
    };

    // Add todo-specific fields
    if (type === 'todo') {
      memory.status = 'pending';
      memory.statusHistory = [{ status: 'pending', timestamp: memory.createdAt }];
    }

    // Create embedding for semantic search
    const embedding = await embeddingService.embed(
      `${type}: ${content}${relatedTo ? ` (related to: ${relatedTo})` : ''}${tags.length > 0 ? ` [tags: ${tags.join(', ')}]` : ''}`
    );

    const point: VectorPoint = {
      id: memory.id,
      vector: embedding,
      payload: {
        ...memory,
        project: projectName,
      },
    };

    await vectorStore.upsert(collectionName, [point]);

    logger.info(`Memory stored: ${type}`, { id: memory.id, project: projectName });
    return memory;
  }

  /**
   * Recall memories by semantic search
   */
  async recall(options: SearchMemoryOptions): Promise<MemorySearchResult[]> {
    const { projectName, query, type = 'all', limit = 5, tag } = options;
    const collectionName = this.getCollectionName(projectName);

    const embedding = await embeddingService.embed(query);

    // Build Qdrant filter
    const mustConditions: Record<string, unknown>[] = [];
    if (type && type !== 'all') {
      mustConditions.push({ key: 'type', match: { value: type } });
    }
    if (tag) {
      mustConditions.push({ key: 'tags', match: { any: [tag] } });
    }

    const filter = mustConditions.length > 0 ? { must: mustConditions } : undefined;

    const results = await vectorStore.search(
      collectionName,
      embedding,
      limit,
      filter
    );

    return results.map(r => ({
      memory: {
        id: r.id,
        type: r.payload.type as MemoryType,
        content: r.payload.content as string,
        tags: (r.payload.tags as string[]) || [],
        relatedTo: r.payload.relatedTo as string | undefined,
        createdAt: r.payload.createdAt as string,
        updatedAt: r.payload.updatedAt as string,
        metadata: r.payload.metadata as Record<string, unknown> | undefined,
        status: r.payload.status as TodoStatus | undefined,
        statusHistory: r.payload.statusHistory as Memory['statusHistory'],
      },
      score: r.score,
    }));
  }

  /**
   * List memories with filters
   */
  async list(options: ListMemoryOptions): Promise<Memory[]> {
    const { projectName, type = 'all', tag, limit = 10 } = options;
    const collectionName = this.getCollectionName(projectName);

    // Use a generic query to get recent memories
    const embedding = await embeddingService.embed(
      type !== 'all' ? `${type} memories` : 'recent memories notes decisions'
    );

    // Build Qdrant filter
    const mustConditions: Record<string, unknown>[] = [];
    if (type && type !== 'all') {
      mustConditions.push({ key: 'type', match: { value: type } });
    }
    if (tag) {
      mustConditions.push({ key: 'tags', match: { any: [tag] } });
    }

    const filter = mustConditions.length > 0 ? { must: mustConditions } : undefined;

    const results = await vectorStore.search(
      collectionName,
      embedding,
      limit,
      filter
    );

    return results.map(r => ({
      id: r.id,
      type: r.payload.type as MemoryType,
      content: r.payload.content as string,
      tags: (r.payload.tags as string[]) || [],
      relatedTo: r.payload.relatedTo as string | undefined,
      createdAt: r.payload.createdAt as string,
      updatedAt: r.payload.updatedAt as string,
      metadata: r.payload.metadata as Record<string, unknown> | undefined,
      status: r.payload.status as TodoStatus | undefined,
      statusHistory: r.payload.statusHistory as Memory['statusHistory'],
    }));
  }

  /**
   * Delete a specific memory
   */
  async forget(projectName: string, memoryId: string): Promise<boolean> {
    const collectionName = this.getCollectionName(projectName);

    try {
      await vectorStore.delete(collectionName, [memoryId]);
      logger.info(`Memory deleted: ${memoryId}`, { project: projectName });
      return true;
    } catch (error) {
      logger.error(`Failed to delete memory: ${memoryId}`, { error });
      return false;
    }
  }

  /**
   * Delete memories by type
   */
  async forgetByType(projectName: string, type: MemoryType): Promise<number> {
    const collectionName = this.getCollectionName(projectName);

    try {
      await vectorStore.deleteByFilter(collectionName, {
        must: [{ key: 'type', match: { value: type } }],
      });
      logger.info(`Memories of type ${type} deleted`, { project: projectName });
      return 1; // Qdrant doesn't return count
    } catch (error) {
      logger.error(`Failed to delete memories by type: ${type}`, { error });
      return 0;
    }
  }

  /**
   * Update todo status
   */
  async updateTodoStatus(
    projectName: string,
    todoId: string,
    status: TodoStatus,
    note?: string
  ): Promise<Memory | null> {
    const collectionName = this.getCollectionName(projectName);

    // First, recall the todo
    const results = await this.recall({
      projectName,
      query: todoId,
      type: 'todo',
      limit: 10,
    });

    const todo = results.find(r => r.memory.id === todoId);
    if (!todo) {
      logger.warn(`Todo not found: ${todoId}`);
      return null;
    }

    // Update the memory
    const updatedMemory: Memory = {
      ...todo.memory,
      status,
      updatedAt: new Date().toISOString(),
      statusHistory: [
        ...(todo.memory.statusHistory || []),
        { status, timestamp: new Date().toISOString(), note },
      ],
    };

    // Re-embed and update
    const embedding = await embeddingService.embed(
      `todo: ${updatedMemory.content} [status: ${status}]${updatedMemory.relatedTo ? ` (related to: ${updatedMemory.relatedTo})` : ''}`
    );

    const point: VectorPoint = {
      id: updatedMemory.id,
      vector: embedding,
      payload: {
        ...updatedMemory,
        project: projectName,
      },
    };

    await vectorStore.upsert(collectionName, [point]);

    logger.info(`Todo status updated: ${todoId} -> ${status}`, { project: projectName });
    return updatedMemory;
  }

  /**
   * Get memory statistics
   */
  async getStats(projectName: string): Promise<{
    total: number;
    byType: Record<MemoryType, number>;
  }> {
    const collectionName = this.getCollectionName(projectName);
    const info = await vectorStore.getCollectionInfo(collectionName);

    // Aggregate real counts by type from collection
    const typeCounts = await vectorStore.aggregateByField(collectionName, 'type');

    return {
      total: info.vectorsCount,
      byType: {
        decision: typeCounts['decision'] || 0,
        insight: typeCounts['insight'] || 0,
        context: typeCounts['context'] || 0,
        todo: typeCounts['todo'] || 0,
        conversation: typeCounts['conversation'] || 0,
        note: typeCounts['note'] || 0,
      },
    };
  }

  /**
   * Batch remember - store multiple memories efficiently
   */
  async batchRemember(
    projectName: string,
    items: Array<Omit<CreateMemoryOptions, 'projectName'>>
  ): Promise<{ saved: Memory[]; errors: string[] }> {
    const collectionName = this.getCollectionName(projectName);
    const saved: Memory[] = [];
    const errors: string[] = [];

    // Create all memories and embeddings in batch
    const memories: Memory[] = [];
    const textsToEmbed: string[] = [];

    for (const item of items) {
      const { content, type = 'note', tags = [], relatedTo, metadata } = item;

      const memory: Memory = {
        id: uuidv4(),
        type,
        content,
        tags,
        relatedTo,
        createdAt: new Date().toISOString(),
        updatedAt: new Date().toISOString(),
        metadata,
      };

      if (type === 'todo') {
        memory.status = 'pending';
        memory.statusHistory = [{ status: 'pending', timestamp: memory.createdAt }];
      }

      memories.push(memory);
      textsToEmbed.push(
        `${type}: ${content}${relatedTo ? ` (related to: ${relatedTo})` : ''}${tags.length > 0 ? ` [tags: ${tags.join(', ')}]` : ''}`
      );
    }

    try {
      // Batch embed all texts
      const embeddings = await embeddingService.embedBatch(textsToEmbed);

      // Create points
      const points: VectorPoint[] = memories.map((memory, i) => ({
        id: memory.id,
        vector: embeddings[i],
        payload: {
          ...memory,
          project: projectName,
        },
      }));

      // Batch upsert
      await vectorStore.upsert(collectionName, points);
      saved.push(...memories);

      logger.info(`Batch remember: ${saved.length} memories saved`, { projectName });
    } catch (error: any) {
      errors.push(`Batch operation failed: ${error.message}`);
      logger.error('Batch remember failed', { error: error.message, projectName });
    }

    return { saved, errors };
  }

  /**
   * Validate auto-extracted memory (mark as user-validated)
   */
  async validateMemory(projectName: string, memoryId: string, validated: boolean): Promise<Memory | null> {
    const collectionName = this.getCollectionName(projectName);

    // Find the memory
    const results = await this.recall({
      projectName,
      query: memoryId,
      limit: 1,
    });

    if (results.length === 0) {
      return null;
    }

    const memory = results[0].memory;
    const updatedMemory: Memory = {
      ...memory,
      validated,
      updatedAt: new Date().toISOString(),
      metadata: {
        ...memory.metadata,
        validatedAt: new Date().toISOString(),
      },
    };

    // Re-embed and update
    const embedding = await embeddingService.embed(
      `${updatedMemory.type}: ${updatedMemory.content}${updatedMemory.relatedTo ? ` (related to: ${updatedMemory.relatedTo})` : ''}`
    );

    const point: VectorPoint = {
      id: updatedMemory.id,
      vector: embedding,
      payload: {
        ...updatedMemory,
        project: projectName,
      },
    };

    await vectorStore.upsert(collectionName, [point]);
    logger.info(`Memory validated: ${memoryId} = ${validated}`, { projectName });

    return updatedMemory;
  }

  /**
   * Merge duplicate/similar memories into consolidated entries
   */
  async mergeMemories(options: {
    projectName: string;
    type?: MemoryType | 'all';
    threshold?: number;
    dryRun?: boolean;
    limit?: number;
  }): Promise<{
    merged: Array<{ original: Memory[]; merged: Memory }>;
    totalFound: number;
    totalMerged: number;
  }> {
    const {
      projectName,
      type = 'all',
      threshold = 0.9,
      dryRun = true,
      limit = 50,
    } = options;

    const collectionName = this.getCollectionName(projectName);
    const result: { merged: Array<{ original: Memory[]; merged: Memory }>; totalFound: number; totalMerged: number } = {
      merged: [],
      totalFound: 0,
      totalMerged: 0,
    };

    try {
      // Scroll through memories to find candidates
      const mustConditions: Record<string, unknown>[] = [];
      if (type && type !== 'all') {
        mustConditions.push({ key: 'type', match: { value: type } });
      }
      const filter = mustConditions.length > 0 ? { must: mustConditions } : undefined;

      const memories: Array<{ id: string; payload: Record<string, unknown> }> = [];
      let offset: string | number | undefined = undefined;

      do {
        const response = await vectorStore['client'].scroll(collectionName, {
          limit: 500,
          offset,
          with_payload: true,
          with_vector: false,
          filter,
        });

        for (const point of response.points) {
          memories.push({ id: point.id as string, payload: point.payload as Record<string, unknown> });
        }

        offset = response.next_page_offset as string | number | undefined;
      } while (offset && memories.length < limit * 10);

      result.totalFound = memories.length;

      if (memories.length < 2) {
        return result;
      }

      // Find clusters of similar memories using recommend
      const processed = new Set<string>();
      const clusters: Memory[][] = [];

      for (const mem of memories) {
        if (processed.has(mem.id)) continue;

        try {
          const similar = await vectorStore.recommend(
            collectionName,
            [mem.id],
            [],
            10
          );

          const cluster: Memory[] = [this.pointToMemory(mem)];
          processed.add(mem.id);

          for (const s of similar) {
            if (s.score >= threshold && !processed.has(s.id)) {
              cluster.push(this.pointToMemory({ id: s.id, payload: s.payload }));
              processed.add(s.id);
            }
          }

          if (cluster.length > 1) {
            clusters.push(cluster);
          }
        } catch {
          // Skip if recommend fails for this point
          processed.add(mem.id);
        }

        if (clusters.length >= limit) break;
      }

      // Merge clusters in parallel batches to avoid timeout
      const BATCH_SIZE = 3;
      const PER_MERGE_TIMEOUT = 30000;
      const mergeStartTime = Date.now();
      const OVERALL_TIMEOUT = 90000; // Leave buffer for HTTP response

      for (let i = 0; i < clusters.length; i += BATCH_SIZE) {
        if (Date.now() - mergeStartTime > OVERALL_TIMEOUT) {
          logger.warn('Memory merge: approaching timeout, stopping early', {
            processed: result.totalMerged,
            remaining: clusters.length - i,
          });
          break;
        }

        const batch = clusters.slice(i, i + BATCH_SIZE);
        const mergeResults = await Promise.allSettled(
          batch.map(cluster =>
            Promise.race([
              this.llmMergeMemories(cluster),
              new Promise<never>((_, reject) =>
                setTimeout(() => reject(new Error('LLM merge timeout')), PER_MERGE_TIMEOUT)
              ),
            ])
          )
        );

        for (let j = 0; j < batch.length; j++) {
          const cluster = batch[j];
          const mergeResult = mergeResults[j];

          // On timeout/error, fallback to concatenation
          const mergedContent = mergeResult.status === 'fulfilled'
            ? mergeResult.value
            : [...new Set(cluster.map(m => m.content.trim()))].join(' | ');

          const mergedMemory: Memory = {
            id: uuidv4(),
            type: cluster[0].type,
            content: mergedContent,
            tags: [...new Set(cluster.flatMap(m => m.tags))],
            relatedTo: cluster.find(m => m.relatedTo)?.relatedTo,
            createdAt: cluster.reduce((earliest, m) =>
              m.createdAt < earliest ? m.createdAt : earliest, cluster[0].createdAt),
            updatedAt: new Date().toISOString(),
            metadata: {
              mergedFrom: cluster.map(m => m.id),
              mergedAt: new Date().toISOString(),
              originalCount: cluster.length,
            },
          };

          result.merged.push({ original: cluster, merged: mergedMemory });

          if (!dryRun) {
            const embedding = await embeddingService.embed(
              `${mergedMemory.type}: ${mergedMemory.content}${mergedMemory.relatedTo ? ` (related to: ${mergedMemory.relatedTo})` : ''}`
            );

            await vectorStore.upsert(collectionName, [{
              id: mergedMemory.id,
              vector: embedding,
              payload: { ...mergedMemory, project: projectName },
            }]);

            const idsToDelete = cluster.map(m => m.id);
            await vectorStore.delete(collectionName, idsToDelete);
          }

          result.totalMerged++;
        }
      }

      logger.info(`Memory merge: ${result.totalMerged} clusters${dryRun ? ' (dry run)' : ' merged'}`, { projectName });
      return result;
    } catch (error: any) {
      if (error.status === 404) {
        return result;
      }
      throw error;
    }
  }

  /**
   * Use LLM to merge multiple memory contents into one consolidated entry
   */
  private async llmMergeMemories(memories: Memory[]): Promise<string> {
    const memoryTexts = memories.map((m, i) => `[${i + 1}] ${m.content}`).join('\n');

    try {
      const result = await llm.complete(
        `Merge the following ${memories.length} related memory entries into a single, concise memory that preserves all unique information:\n\n${memoryTexts}`,
        {
          systemPrompt: 'You are a memory consolidation assistant. Merge related memories into one concise entry. Preserve all unique facts, decisions, and insights. Remove redundancy. Output only the merged text, nothing else.',
          maxTokens: 500,
          temperature: 0.3,
        }
      );
      return result.text.trim();
    } catch {
      // Fallback: concatenate with dedup
      const seen = new Set<string>();
      const parts: string[] = [];
      for (const m of memories) {
        const normalized = m.content.trim().toLowerCase();
        if (!seen.has(normalized)) {
          seen.add(normalized);
          parts.push(m.content.trim());
        }
      }
      return parts.join(' | ');
    }
  }

  /**
   * Convert a raw Qdrant point to a Memory object
   */
  private pointToMemory(point: { id: string; payload: Record<string, unknown> }): Memory {
    return {
      id: point.id,
      type: point.payload.type as MemoryType,
      content: point.payload.content as string,
      tags: (point.payload.tags as string[]) || [],
      relatedTo: point.payload.relatedTo as string | undefined,
      createdAt: point.payload.createdAt as string,
      updatedAt: point.payload.updatedAt as string,
      metadata: point.payload.metadata as Record<string, unknown> | undefined,
      status: point.payload.status as TodoStatus | undefined,
      statusHistory: point.payload.statusHistory as Memory['statusHistory'],
      source: point.payload.source as MemorySource | undefined,
      confidence: point.payload.confidence as number | undefined,
      validated: point.payload.validated as boolean | undefined,
    };
  }

  /**
   * Get unvalidated auto-extracted memories for review
   */
  async getUnvalidatedMemories(projectName: string, limit: number = 20): Promise<Memory[]> {
    const collectionName = this.getCollectionName(projectName);

    try {
      // Search for memories that were auto-extracted and not yet validated
      const embedding = await embeddingService.embed('auto extracted memories unvalidated');

      const results = await vectorStore.search(
        collectionName,
        embedding,
        limit * 2, // Get more to filter
        {
          must: [
            { key: 'validated', match: { value: false } },
          ],
        }
      );

      return results
        .filter(r => r.payload.source && (r.payload.source as string).startsWith('auto_'))
        .slice(0, limit)
        .map(r => ({
          id: r.id,
          type: r.payload.type as MemoryType,
          content: r.payload.content as string,
          tags: (r.payload.tags as string[]) || [],
          relatedTo: r.payload.relatedTo as string | undefined,
          createdAt: r.payload.createdAt as string,
          updatedAt: r.payload.updatedAt as string,
          metadata: r.payload.metadata as Record<string, unknown> | undefined,
          source: r.payload.source as MemorySource,
          confidence: r.payload.confidence as number,
          validated: r.payload.validated as boolean,
        }));
    } catch (error: any) {
      if (error.status === 404) {
        return [];
      }
      throw error;
    }
  }
}

export const memoryService = new MemoryService();
export default memoryService;
